{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACGAN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from pytorch_gan_metrics import get_inception_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CIFAR10 dataset...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def create_CIFAR10_dataloaders(batch_size): \n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(), \n",
    "        torchvision.transforms.Resize(32), \n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    train_CIFAR10_set = torchvision.datasets.CIFAR10(root='./cifar10/', train=True, download=True, transform=transform)\n",
    "    test_CIFAR10_set = torchvision.datasets.CIFAR10(root='./cifar10/', train=False, download=True, transform=transform)\n",
    "\n",
    "    train_CIFAR10_dataloader = DataLoader(train_CIFAR10_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_CIFAR10_dataloader = DataLoader(test_CIFAR10_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    return train_CIFAR10_dataloader, test_CIFAR10_dataloader\n",
    "\n",
    "print(\"Downloading CIFAR10 dataset...\")\n",
    "batch_size = 64\n",
    "train_dataloader, test_dataloader = create_CIFAR10_dataloaders(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating DCGAN generator and discriminator...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Generator_ACGAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator_ACGAN, self).__init__()\n",
    "        self.emb = nn.Embedding(10, 100)\n",
    "        self.fc = nn.Linear(100, 128 * 8 ** 2)\n",
    "        self.main = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 3, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        x = torch.mul(self.emb(labels), noise)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.shape[0], 128, 8, 8)\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "class Discriminator_ACGAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator_ACGAN, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            *discriminator_block(3, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * 2 ** 2, 1), nn.Sigmoid())\n",
    "        self.aux_layer = nn.Sequential(nn.Linear(128 * 2 ** 2, 10), nn.Softmax())\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.main(img)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        validity = self.adv_layer(x)\n",
    "        label = self.aux_layer(x)\n",
    "        return validity, label\n",
    "\n",
    "\n",
    "print(\"Instantiating DCGAN generator and discriminator...\")\n",
    "acgan_generator = Generator_ACGAN()\n",
    "acgan_discriminator = Discriminator_ACGAN()\n",
    "acgan_generator.to(device)\n",
    "acgan_discriminator.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=50\n",
    "learning_rate = 2e-4\n",
    "\n",
    "def train(generator, discriminator, train_dataloader):\n",
    "    source_criterion = nn.BCELoss()\n",
    "    class_criterion = nn.NLLLoss()\n",
    "    optim_generator = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "    optim_discriminator = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "    if not os.path.exists('train_generated_images_acgan_real/'): \n",
    "        os.makedirs('train_generated_images_acgan_real')\n",
    "    if not os.path.exists('train_generated_images_acgan_fake/'): \n",
    "        os.makedirs('train_generated_images_acgan_fake')\n",
    "        \n",
    "    inception_score_file = open(\"inception_score_acgan.csv\", \"w\")\n",
    "    inception_score_file.write('epoch, inception_score \\n')\n",
    "\n",
    "    for epoch in tqdm(range(epochs)): \n",
    "        for images, labels in train_dataloader:\n",
    "            batch_size = images.shape[0]\n",
    "            real_images = Variable(images.type(torch.cuda.FloatTensor)).to(device)\n",
    "            real_labels = Variable(labels.type(torch.cuda.LongTensor)).to(device)\n",
    "\n",
    "            # adversarial ground truth\n",
    "            fake = torch.zeros(batch_size).to(device)\n",
    "            valid = torch.ones(batch_size).to(device)\n",
    "\n",
    "            ### train generator\n",
    "            optim_generator.zero_grad()\n",
    "            z = Variable(torch.cuda.FloatTensor(np.random.normal(0, 1, (batch_size, 100))))\n",
    "            generated_labels = Variable(torch.cuda.LongTensor(np.random.randint(0, 10, batch_size)))\n",
    "\n",
    "            # generate image batch\n",
    "            generated_images = generator(z, generated_labels)\n",
    "\n",
    "            # compute generator loss, optimize generator\n",
    "            validity, predicted_label = discriminator(generated_images)\n",
    "            gen_loss = 0.5 * (source_criterion(validity, valid.unsqueeze(1)) + class_criterion(predicted_label, generated_labels))\n",
    "            gen_loss.backward()\n",
    "            optim_generator.step()\n",
    "\n",
    "            ### train discriminator\n",
    "            optim_discriminator.zero_grad()\n",
    "\n",
    "            # compute real images loss\n",
    "            real_pred, real_aux = discriminator(real_images)\n",
    "            disc_loss_real = 0.5 * (source_criterion(real_pred, valid.unsqueeze(1)) + class_criterion(real_aux, real_labels))\n",
    "\n",
    "            # compute fake images loss\n",
    "            fake_pred, fake_aux = discriminator(generated_images.detach())\n",
    "            disc_loss_fake = 0.5 * (source_criterion(fake_pred, fake.unsqueeze(1)) + class_criterion(fake_aux, generated_labels))\n",
    "\n",
    "            # compute overall discriminator loss, optimize discriminator\n",
    "            disc_loss = 0.5 * (disc_loss_real + disc_loss_fake)\n",
    "            disc_loss.backward()\n",
    "            optim_discriminator.step()\n",
    "\n",
    "        # compute inception score and samples every epoch\n",
    "        z = Variable(torch.cuda.FloatTensor(np.random.normal(0, 1, (batch_size, 100))))\n",
    "        generated_labels = Variable(torch.cuda.LongTensor(np.random.randint(0, 10, batch_size)))\n",
    "        samples = generator(z, generated_labels)\n",
    "\n",
    "        # normalize to [0, 1]\n",
    "        samples = samples.mul(0.5).add(0.5)\n",
    "        \n",
    "        assert 0 <= samples.min() and samples.max() <= 1\n",
    "        inception_score, inception_score_std = get_inception_score(samples)\n",
    "        print(\"epoch: \" + str(epoch) + ', inception score: ' + str(round(inception_score, 2)) + ' ± ' + str(round(inception_score_std, 2)))\n",
    "\n",
    "        samples = samples[:64].data.cpu()\n",
    "        utils.save_image(samples, 'train_generated_images_acgan_fake/epoch_{}.png'.format(str(epoch)))\n",
    "        utils.save_image(real_images, 'train_generated_images_acgan_real/epoch_{}.png'.format(str(epoch)))\n",
    "        \n",
    "        inception_score_file.write(str(epoch) + ', ' + str(round(inception_score, 2)) + '\\n')\n",
    "\n",
    "    inception_score_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ACGAN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]c:\\Users\\FJ\\.conda\\envs\\cpsc-8430\\lib\\site-packages\\torch\\nn\\modules\\container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "  2%|▏         | 1/50 [01:06<53:56, 66.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, inception score: 1.59 ± 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [01:38<37:07, 46.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, inception score: 1.44 ± 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [01:57<26:23, 33.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, inception score: 1.73 ± 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [02:16<21:27, 27.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, inception score: 1.62 ± 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [02:37<19:01, 25.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, inception score: 1.65 ± 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [02:57<17:16, 23.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, inception score: 1.7 ± 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [03:31<19:21, 27.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, inception score: 1.54 ± 0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [04:08<21:05, 30.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, inception score: 1.58 ± 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [04:44<21:53, 32.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, inception score: 1.57 ± 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [05:03<18:43, 28.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, inception score: 1.63 ± 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [05:22<16:27, 25.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, inception score: 1.81 ± 0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [05:43<15:12, 24.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, inception score: 1.76 ± 0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [06:16<16:25, 26.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, inception score: 1.72 ± 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [06:42<15:50, 26.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, inception score: 1.65 ± 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [07:02<14:24, 24.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, inception score: 1.77 ± 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [07:22<13:09, 23.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, inception score: 1.79 ± 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [07:42<12:07, 22.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16, inception score: 1.58 ± 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [08:01<11:19, 21.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17, inception score: 1.89 ± 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [08:20<10:38, 20.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18, inception score: 1.91 ± 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [08:39<10:07, 20.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19, inception score: 1.67 ± 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [08:59<09:37, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20, inception score: 1.65 ± 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [09:18<09:09, 19.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21, inception score: 1.76 ± 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [09:37<08:44, 19.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22, inception score: 1.78 ± 0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [09:56<08:24, 19.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23, inception score: 1.77 ± 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [10:15<08:03, 19.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24, inception score: 1.8 ± 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [10:35<07:51, 19.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25, inception score: 1.75 ± 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [11:06<08:44, 22.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26, inception score: 1.77 ± 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [11:45<10:09, 27.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27, inception score: 1.83 ± 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [12:27<11:13, 32.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28, inception score: 2.0 ± 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [12:49<09:41, 29.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29, inception score: 1.77 ± 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [13:09<08:20, 26.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30, inception score: 1.83 ± 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [13:30<07:26, 24.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31, inception score: 1.81 ± 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [14:06<07:59, 28.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32, inception score: 1.95 ± 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [14:27<06:54, 25.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33, inception score: 1.87 ± 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [15:03<07:12, 28.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34, inception score: 1.83 ± 0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [15:29<06:34, 28.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35, inception score: 1.97 ± 0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [15:49<05:33, 25.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36, inception score: 1.83 ± 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [16:09<04:46, 23.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37, inception score: 1.87 ± 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [16:29<04:11, 22.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38, inception score: 1.9 ± 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [16:50<03:41, 22.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39, inception score: 2.01 ± 0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [17:14<03:26, 22.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40, inception score: 1.82 ± 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [17:35<02:56, 22.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41, inception score: 1.9 ± 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [17:56<02:32, 21.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42, inception score: 2.02 ± 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [18:16<02:08, 21.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43, inception score: 1.9 ± 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [18:38<01:47, 21.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44, inception score: 1.83 ± 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [19:00<01:26, 21.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45, inception score: 1.83 ± 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [19:21<01:04, 21.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46, inception score: 1.83 ± 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [19:45<00:44, 22.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47, inception score: 1.84 ± 0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [20:06<00:21, 21.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48, inception score: 1.73 ± 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [20:37<00:00, 24.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49, inception score: 2.04 ± 0.26\n",
      "saving ACGAN model to file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train ACGAN\n",
    "print(\"training ACGAN model...\")\n",
    "train(acgan_generator, acgan_discriminator, train_dataloader)\n",
    "\n",
    "# save ACGAN to file\n",
    "#print(\"saving ACGAN model to file...\")\n",
    "#torch.save(acgan_generator.state_dict(), 'acgan_generator.pkl')\n",
    "#torch.save(acgan_discriminator.state_dict(), 'acgan_discriminator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ACGAN model...\n",
      "Grid of 8x8 images saved to 'acgan_generated_images.png'.\n"
     ]
    }
   ],
   "source": [
    "def generate_images(generator):\n",
    "    z = Variable(torch.cuda.FloatTensor(np.random.normal(0, 1, (batch_size, 100))))\n",
    "    generated_labels = Variable(torch.cuda.LongTensor(np.random.randint(0, 10, batch_size)))\n",
    "    samples = generator(z, generated_labels)\n",
    "    \n",
    "    samples = samples.mul(0.5).add(0.5)\n",
    "    samples = samples.data.cpu()\n",
    "    grid = utils.make_grid(samples)\n",
    "    print(\"Grid of 8x8 images saved to 'acgan_generated_images.png'.\")\n",
    "    utils.save_image(grid, 'acgan_generated_images.png')\n",
    "\n",
    "def load_model(model, model_filename): \n",
    "    model.load_state_dict(torch.load(model_filename))\n",
    "\n",
    "# load trained model and generate sample images\n",
    "print(\"loading ACGAN model...\")\n",
    "load_model(acgan_generator, 'acgan_generator.pkl')\n",
    "load_model(acgan_discriminator, 'acgan_discriminator.pkl')\n",
    "\n",
    "generate_images(acgan_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc-8430",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
